## Определение токсичности комментариев
### Описание проекта
Некий интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Наша задача - обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок. По требованию заказчика, значение метрики F1 должно быть не меньше 0.75.
### Используемые библиотеки и инструменты
- NumPy
- Pandas
- Matplotlib
- Seaborn
- Sklearn
- NLTK
- DecisionTreeClassifier
- RandomForestClassifier
- LogisticRegression
- RandomizedSearchCV
- TfidfVectorizer
- CountVectorizer
- WordNetLemmatizer
- nltk_stopwords
- CatBoostClassifier
- lightgbm
### Вывод
Самый высокий показатель F1 у LGBMClassifier! С вероятностью 0.75 он идентифицирует токсичные комментарии, которые можно отправлять на модерацию!
